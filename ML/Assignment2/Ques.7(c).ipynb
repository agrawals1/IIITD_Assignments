{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17b50c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score \n",
    "from sklearn.metrics import recall_score \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4161015",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]\n",
    "y_p = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0b37caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making confusion Matrix to get true positive, true negative, false positive and false negative\n",
    "cm = confusion_matrix(y_t, y_p)\n",
    "tn, fp, fn, tp = cm[0][0], cm[0][1], cm[1][0], cm[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d41438cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.5, recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "#calculating precision recall using formula\n",
    "precision1 = tp / (tp+fp)\n",
    "recall1 = tp / (tp+fn)\n",
    "\n",
    "print(f\"precision: {precision1}, recall: {recall1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cae519e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f0.5-score: 0.5555555555555556, f1-score: 0.6666666666666666, f5-score: 0.9629629629629629\n"
     ]
    }
   ],
   "source": [
    "#CALCULATING fBeta scores using formula\n",
    "f05_score = (1.25 * precision1 * recall1) / (0.25 * precision1 + recall1)\n",
    "f1_score = (2 * precision1 * recall1) / (precision1 + recall1)\n",
    "f5_score = (26 * precision1 * recall1) / (25 * precision1 + recall1)\n",
    "\n",
    "print(f\"f0.5-score: {f05_score}, f1-score: {f1_score}, f5-score: {f5_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4e8ea24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values using Formula\n",
      "\n",
      "precision: 0.5, recall: 1.0, f0.5-score: 0.5555555555555556, f1-score: 0.6666666666666666, f5-score: 0.9629629629629629\n",
      "\n",
      "Values using library function\n",
      "precision: 0.5, recall: 1.0, f0.5-score: 0.5555555555555556, f1-score: 0.6666666666666666, f5-score: 0.9629629629629629\n"
     ]
    }
   ],
   "source": [
    "#calculating precision, recall, f0.5 score, f1-score, f5-score using in-build libraries\n",
    "precision = precision_score(y_t, y_p)\n",
    "recall = recall_score(y_t, y_p)\n",
    "\n",
    "\n",
    "f_05_score = fbeta_score(y_t, y_p, beta=0.5)\n",
    "\n",
    "f_1_score = fbeta_score(y_t, y_p, beta=1.0)\n",
    "\n",
    "f_5_score = fbeta_score(y_t, y_p, beta=5.0)\n",
    "\n",
    "print(\"Values using Formula\\n\")\n",
    "print(f\"precision: {precision1}, recall: {recall1}, f0.5-score: {f05_score}, f1-score: {f1_score}, f5-score: {f5_score}\")\n",
    "\n",
    "print(\"\\nValues using library function\")\n",
    "print(f\"precision: {precision}, recall: {recall}, f0.5-score: {f_05_score}, f1-score: {f_1_score}, f5-score: {f_5_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
